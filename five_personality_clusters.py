# -*- coding: utf-8 -*-
"""five_personality_clusters.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1JzQfNU681bZzyN7XZSZJuUM03Oy8kkNE

# Five Personality Traits (OCEAN)

* Openness to experience (inventive/curious vs. consistent/cautious)
* Conscientiousness (efficient/organized vs. easy-going/careless)
* Extroversion (outgoing/energetic vs. solitary/reserved)
* Agreeableness (friendly/compassionate vs. challenging/detached)
* Neuroticism (sensitive/nervous vs. secure/confident)

Link para projeto e base de dados: https://www.kaggle.com/tunguz/big-five-personality-test

Importando as bibliotecas
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import os
from io import open
pd.options.display.max_columns = 150

"""Carregando o Dataset"""

data = pd.read_csv('data-final.csv', sep='\t')

"""Verificando o dataset"""

data.head()

"""Excluindo os atributos irrelevantes"""

data.drop(data.columns[50:110], axis=1, inplace=True)

#data.drop(data.columns[50:], axis=1, inplace=True)

"""Verificando novamente os dados"""

data.head()

data["EXT1"].value_counts()

"""Analisando estatísticas da base de dados."""

pd.options.display.float_format = "{:.2f}".format
data.describe()

"""Verificando a contagem de registros por valor."""



data["EXT1"].value_counts()

"""Selecionando o total de registros com o valor zero."""

data[(data == 0.00).all(axis=1)].describe()

"""Limpando o Dataframe com apenas registros maiores que zero."""

data = data[(data > 0.00).all(axis=1)]

"""Verificando a contagem de registros por valor."""

data["EXT1"].value_counts()

"""#### Qual o número de clusters que vamos definir?

Instalando a yellowbrick
"""

!pip install yellowbrick

"""Importando as bibliotecas que iremos trabalhar"""

from sklearn.cluster import KMeans
from yellowbrick.cluster import KElbowVisualizer

"""Instanciando o método KMeans e o Visualizer."""

kmeans = KMeans()
visualizer = KElbowVisualizer(kmeans, k=(2,10))

"""Selecionando uma amostra aleatória dos dados com 5000 observações."""

data_sample = data.sample(n=5000, random_state=1)

"""### Executando o teste."""

visualizer.fit(data_sample)
visualizer.poof()

"""### Agrupando os  participantes em 5 grupos

Atribuindo os registros aos devidos grupos
"""

kmeans = KMeans(n_clusters=5)
k_fit = kmeans.fit(data)

"""Inserindo os rótulos dos clusters no dataframe"""

predicoes = k_fit.labels_
data['Clusters'] = predicoes

"""Verificando os dados"""

data.head()

"""### Analisando os grupos

Qual a quantidade de observações em cada grupo?
"""

data["Clusters"].value_counts()

"""Agrupando os registros por grupos"""

data.groupby('Clusters').mean()

"""Calculando a média de cada grupo de questões para verificar um padrão.

Selecionando as colunas de cada grupo.
"""

col_list = list(data)
ext = col_list[0:10]
est = col_list[10:20]
agr = col_list[20:30]
csn = col_list[30:40]
opn = col_list[40:50]

"""Somando os valores de cada grupo"""

data_soma = pd.DataFrame()
data_soma['extroversion'] = data[ext].sum(axis=1)/10
data_soma['neurotic'] = data[est].sum(axis=1)/10
data_soma['agreeable'] = data[agr].sum(axis=1)/10
data_soma['conscientious'] = data[csn].sum(axis=1)/10
data_soma['open'] = data[opn].sum(axis=1)/10
data_soma['clusters'] = predicoes

"""Exibindo o valor médio por grupo"""

data_soma.groupby('clusters').mean()

"""Visualizando as médias por grupo."""

data_clusters = data_soma.groupby('clusters').mean()

plt.figure(figsize=(22,3))
for i in range(0, 5):
    plt.subplot(1,5,i+1)
    plt.bar(data_clusters.columns, data_clusters.iloc[:, i], color='green', alpha=0.2)
    plt.plot(data_clusters.columns, data_clusters.iloc[:, i], color='red')
    plt.title('Grupo ' + str(i))
    plt.xticks(rotation=45)
    plt.ylim(0,4);

"""Criando uma planilha para entrar com os dados"""

data[:0].to_excel("perguntas.xlsx",index=False)

"""Recuperando os dados"""

meus_dados = pd.read_excel('perguntas.xlsx')

"""Passando meus dados para o modelo"""

grupo_personalidade = k_fit.predict(meus_dados)[0]
print('Meu grupo de personalidade é: ', grupo_personalidade)

"""Outra forma mais interessante...

Instalando a biblioteca gradio
"""

!pip install gradio

import gradio as gr

"""Lendo os dados com as questões."""

dicio_questions = open("questions.txt").read().split("\n")

"""Verificando os dados."""

dicio_questions

"""Limpando os dados e recuperando apenas as questões"""

questions = []
for q in dicio_questions:
  q = str(q)
  questions.append(q[q.find("\t"):].lstrip())

questions

"""Criando os inputs dinamicos para passar ao gradio"""

inputs_questions = []
for q in questions:
  obj_input = gr.inputs.Slider(minimum=1,maximum=5,step=1,default=3,label=q)
  inputs_questions.append(obj_input)

"""Verificando os inputs"""

inputs_questions

"""Criando a interface e a função predict."""

def predict(*outputs_questions):
    outputs_questions = np.array(outputs_questions).reshape(1, -1)
    return k_fit.predict(outputs_questions)

iface = gr.Interface(
                    fn = predict,
                    title = "Big Five Personality",
                    description = "Sistema para detecção de traços de personalidade.",
                    inputs = inputs_questions,
                    outputs="text")
iface.launch(share=True)

